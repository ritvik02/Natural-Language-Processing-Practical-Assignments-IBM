{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analysising word sense</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: wn==0.0.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (0.0.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U wn==0.0.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python word sense disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pywsd in c:\\users\\user\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from pywsd) (1.15.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from pywsd) (1.19.5)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (from pywsd) (3.4.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (from pywsd) (0.25.1)\n",
      "Requirement already satisfied: wn in c:\\users\\user\\anaconda3\\lib\\site-packages (from pywsd) (0.0.23)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->pywsd) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->pywsd) (2019.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pywsd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordnet in c:\\users\\user\\anaconda3\\lib\\site-packages (0.0.1b2)\n",
      "Requirement already satisfied: colorama==0.3.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from wordnet) (0.3.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 10.152114152908325 secs.\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "import pywsd\n",
    "from nltk.corpus import wordnet as wn\n",
    "from pywsd.lesk import simple_lesk\n",
    "import codecs\n",
    "import wordnet\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from pywsd import disambiguate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordnet is like a english dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('room.n.01'),\n",
       " Synset('room.n.02'),\n",
       " Synset('room.n.03'),\n",
       " Synset('room.n.04'),\n",
       " Synset('board.v.02')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns=wn.synsets('room') #synset is to look up words in the wordnet. it will give us different meanings/senses of the word we have passed\n",
    "syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'opportunity for'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns[2].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms1=[]\n",
    "antonyms1=[]\n",
    "for syn in wn.synsets('good'):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms1.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms1.append(l.antonyms()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['good',\n",
       "  'good',\n",
       "  'goodness',\n",
       "  'good',\n",
       "  'goodness',\n",
       "  'commodity',\n",
       "  'trade_good',\n",
       "  'good',\n",
       "  'good',\n",
       "  'full',\n",
       "  'good',\n",
       "  'good',\n",
       "  'estimable',\n",
       "  'good',\n",
       "  'honorable',\n",
       "  'respectable',\n",
       "  'beneficial',\n",
       "  'good',\n",
       "  'good',\n",
       "  'good',\n",
       "  'just',\n",
       "  'upright',\n",
       "  'adept',\n",
       "  'expert',\n",
       "  'good',\n",
       "  'practiced',\n",
       "  'proficient',\n",
       "  'skillful',\n",
       "  'skilful',\n",
       "  'good',\n",
       "  'dear',\n",
       "  'good',\n",
       "  'near',\n",
       "  'dependable',\n",
       "  'good',\n",
       "  'safe',\n",
       "  'secure',\n",
       "  'good',\n",
       "  'right',\n",
       "  'ripe',\n",
       "  'good',\n",
       "  'well',\n",
       "  'effective',\n",
       "  'good',\n",
       "  'in_effect',\n",
       "  'in_force',\n",
       "  'good',\n",
       "  'good',\n",
       "  'serious',\n",
       "  'good',\n",
       "  'sound',\n",
       "  'good',\n",
       "  'salutary',\n",
       "  'good',\n",
       "  'honest',\n",
       "  'good',\n",
       "  'undecomposed',\n",
       "  'unspoiled',\n",
       "  'unspoilt',\n",
       "  'good',\n",
       "  'well',\n",
       "  'good',\n",
       "  'thoroughly',\n",
       "  'soundly',\n",
       "  'good'],\n",
       " ['evil', 'evilness', 'bad', 'badness', 'bad', 'evil', 'ill'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms1,antonyms1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=wn.synset('sport.n.01')\n",
    "w2=wn.synset('football.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.wup_similarity(w2) #we are checking that how much are the two words similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filteredSentence(sentence):\n",
    "    filtered_sent=[]\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    ps=PorterStemmer()\n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    words=word_tokenize(sentence)\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(lemmatizer.lemmatize(ps.stem(w)))\n",
    "            for i in synonymsCreator(w):\n",
    "                filtered_sent.append(i)\n",
    "    return filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add synonyms to match list\n",
    "def synonymsCreator(word):\n",
    "    synonyms=[]\n",
    "    for syn in wn.synsets(word):\n",
    "        for i in syn.lemmas():\n",
    "            synonyms.append(i.name())\n",
    "    return set(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityCheck(word1,word2):\n",
    "    word1=word1+\".n.01\"\n",
    "    word2=word2+\".n.01\"\n",
    "    try:\n",
    "        w1=wordnet.synset(word1)\n",
    "        w2=wordnet.synset(word2)\n",
    "        return w1.wup_similarity(w2)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to remove stopwords, lemmatize\n",
    "def simpleFilter(sentence):\n",
    "    filtered_sent=[]\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    words=word_tokenize(sentence)\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(lemmatizer.lemmatize(w))\n",
    "    return set(filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read text file\n",
    "cricfile=codecs.open(r'E:\\user backup\\Desktop\\CODING\\IBM\\NLP\\Pracs\\bat1.txt','r','utf-8')\n",
    "sent2=cricfile.read().lower()\n",
    "vampirefile=codecs.open(r'E:\\user backup\\Desktop\\CODING\\IBM\\NLP\\Pracs\\bat2.txt','r','utf-8')\n",
    "sent1=vampirefile.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter query: I like sports\n",
      "Cricket Bat\n",
      "Enter Query: It is flying\n",
      "Mammal Bat\n",
      "Enter Query: end\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "#read query from user\n",
    "sent3=input(\"Enter query: \").lower()\n",
    "while(sent3!=\"end\"):\n",
    "    filtered_sent1=[]\n",
    "    filtered_sent2=[]\n",
    "    filtered_sent3=[]\n",
    "    counter1=0\n",
    "    counter2=0\n",
    "    sent31_similarity=0\n",
    "    sent32_similarity=0\n",
    "    filtered_sent1=simpleFilter(sent1)\n",
    "    filtered_sent2=simpleFilter(sent2)\n",
    "    filtered_sent3=simpleFilter(sent3)\n",
    "    \n",
    "    #for similarity\n",
    "    for i in filtered_sent3:\n",
    "        for j in filtered_sent1:\n",
    "            #counter1=counter1+1\n",
    "            sent31_similarity=sent31_similarity+similarityCheck(i,j)\n",
    "        for j in filtered_sent2:\n",
    "            #counter2=counter2+1\n",
    "            sent32_similarity=sent32_similarity+similarityCheck(i,j)\n",
    "            \n",
    "    filtered_sent1=[]\n",
    "    filtered_sent2=[]\n",
    "    filtered_sent3=[]\n",
    "    \n",
    "    #for synonyms\n",
    "    filtered_sent1=filteredSentence(sent1)\n",
    "    #print(filtered_sent1)\n",
    "    filtered_sent2=filteredSentence(sent2)\n",
    "    #print(filtered_sent2)\n",
    "    filtered_sent3=filteredSentence(sent3)\n",
    "    #print(filtered_sent3)\n",
    "    sent1_count=0\n",
    "    sent2_count=0\n",
    "    for i in filtered_sent3:\n",
    "        for j in filtered_sent1:\n",
    "            if (i==j):\n",
    "                sent1_count=sent1_count+1\n",
    "        for j in filtered_sent2:\n",
    "            if (i==j):\n",
    "                sent2_count=sent2_count+1\n",
    "    \n",
    "    if((sent1_count+sent31_similarity)>(sent2_count+sent32_similarity)):\n",
    "        print(\"Mammal Bat\")\n",
    "    else:\n",
    "        print(\"Cricket Bat\")\n",
    "    sent3=input(\"Enter Query: \").lower()\n",
    "print(\"Terminated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context for I went to the bank to deposit my money\n",
      "Synset('depository_financial_institution.n.01')\n",
      "a financial institution that accepts deposits and channels the money into lending activities\n"
     ]
    }
   ],
   "source": [
    "sentence=['I went to the bank to deposit my money',\n",
    "'The river bank was full of dead fishes']\n",
    "print('context for',sentence[0])\n",
    "answer=simple_lesk(sentence[0],'bank')\n",
    "print(answer)\n",
    "print(answer.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context for The river bank was full of dead fishes\n",
      "Synset('bank.n.01')\n",
      "sloping land (especially the slope beside a body of water)\n"
     ]
    }
   ],
   "source": [
    "print('context for',sentence[1])\n",
    "answer=simple_lesk(sentence[1],'bank')\n",
    "print(answer)\n",
    "print(answer.definition())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
