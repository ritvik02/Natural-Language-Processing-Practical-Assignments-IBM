{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Assignment 5 - POS(Part of Speech) Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most basic model is the bag of words model\n",
    "I LIKE YOU\n",
    "I AM LIKE YOU #LIKE functioning differently in both cases\n",
    "#so by using pos we are trying yo understand how a word is being used in a sentence\n",
    "#POS tagging also used for building lemmatisers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are doing POS tagging using the CRF CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\ritvi\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - sklearn-crfsuite\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.10.0               |   py37h03978a9_1         3.1 MB  conda-forge\n",
      "    python-crfsuite-0.9.7      |   py37h1fb7aa8_1         175 KB  conda-forge\n",
      "    sklearn-crfsuite-0.3.6     |     pyh9f0ad1d_0          12 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  python-crfsuite    conda-forge/win-64::python-crfsuite-0.9.7-py37h1fb7aa8_1\n",
      "  sklearn-crfsuite   conda-forge/noarch::sklearn-crfsuite-0.3.6-pyh9f0ad1d_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                                4.9.2-py37h03978a9_0 --> 4.10.0-py37h03978a9_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "python-crfsuite-0.9. | 175 KB    |            |   0% \n",
      "python-crfsuite-0.9. | 175 KB    | 9          |   9% \n",
      "python-crfsuite-0.9. | 175 KB    | ######4    |  64% \n",
      "python-crfsuite-0.9. | 175 KB    | ########## | 100% \n",
      "\n",
      "conda-4.10.0         | 3.1 MB    |            |   0% \n",
      "conda-4.10.0         | 3.1 MB    | 1          |   2% \n",
      "conda-4.10.0         | 3.1 MB    | 4          |   5% \n",
      "conda-4.10.0         | 3.1 MB    | 9          |  10% \n",
      "conda-4.10.0         | 3.1 MB    | ##1        |  22% \n",
      "conda-4.10.0         | 3.1 MB    | ##9        |  29% \n",
      "conda-4.10.0         | 3.1 MB    | ###7       |  37% \n",
      "conda-4.10.0         | 3.1 MB    | ####5      |  46% \n",
      "conda-4.10.0         | 3.1 MB    | #####2     |  53% \n",
      "conda-4.10.0         | 3.1 MB    | ######6    |  67% \n",
      "conda-4.10.0         | 3.1 MB    | #######6   |  77% \n",
      "conda-4.10.0         | 3.1 MB    | ########6  |  86% \n",
      "conda-4.10.0         | 3.1 MB    | ########## | 100% \n",
      "conda-4.10.0         | 3.1 MB    | ########## | 100% \n",
      "\n",
      "sklearn-crfsuite-0.3 | 12 KB     |            |   0% \n",
      "sklearn-crfsuite-0.3 | 12 KB     | ########## | 100% \n",
      "sklearn-crfsuite-0.3 | 12 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tagging using CRF\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF,metrics\n",
    "from collections import Counter\n",
    "print('POS Tagging using CRF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sentences = nltk.corpus.treebank.tagged_sents(tagset='universal')#getting a pre-existing database from the nltk corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences #so we have a database where every word is already tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3914"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_sentences) #no of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged words :  100676\n"
     ]
    }
   ],
   "source": [
    "print(\"Tagged words : \",len(nltk.corpus.treebank.tagged_words()))#no of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged words :  100676\n"
     ]
    }
   ],
   "source": [
    "tagged_words = [tup for sent in tagged_sentences for tup in sent]\n",
    "print(\"Tagged words : \",len(nltk.corpus.treebank.tagged_words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = set([tag for word,tag in tagged_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'X'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags #to get all the universal tags in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,test_set = train_test_split(tagged_sentences,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3131"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('``', '.'),\n",
       " ('If', 'ADP'),\n",
       " ('we', 'PRON'),\n",
       " ('have', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('real', 'ADJ'),\n",
       " ('bad', 'ADJ'),\n",
       " ('day', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('program', 'NOUN'),\n",
       " ('would', 'VERB'),\n",
       " ('say', 'VERB'),\n",
       " (',', '.'),\n",
       " ('`', '.'),\n",
       " ('*', 'X'),\n",
       " ('Buy', 'VERB'),\n",
       " (',', '.'),\n",
       " (\"'\", '.'),\n",
       " (\"''\", '.'),\n",
       " ('he', 'PRON'),\n",
       " ('explains', 'VERB'),\n",
       " ('*T*-1', 'X'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[{\"metadata\":{\"trusted\":true},\"cell_type\":\"code\",\"source\":\"tagged_words=[tup for sent in tagged_sentences for tup in sent]\\nprint(len(tagged_words))\\nprint(\\\"Tagged words:\\\", len(nltk.corpus.treebank.tagged_words()))\",\"execution_count\":12,\"outputs\":[{\"output_type\":\"stream\",\"text\":\"100676\\nTagged words: 100676\\n\",\"name\":\"stdout\"}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[{\"metadata\":{\"trusted\":true},\"cell_type\":\"code\",\"source\":\"tagged_words=[tup for sent in tagged_sentences for tup in sent]\\nprint(len(tagged_words))\\n\n",
    "#print(\\\"Tagged words:\\\", len(nltk.corpus.treebank.tagged_words()))\",\"execution_count\":12,\"outputs\":[{\"output_type\":\"stream\",\"text\":\"100676\\nTagged words: 100676\\n\",\"name\":\"stdout\"}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the fetures\n",
    "#we are passing the sentence and the words in that particular sentence in the feature function. if there are 4 words then the index will be 0 to 3\n",
    "def features(sentence,index):\n",
    "    return{\n",
    "        'is_first_capital':int(sentence[index][0].isupper()),\n",
    "        'is_first_word':int(index==0),\n",
    "        'is_last_word':int(index==len(sentence)-1),\n",
    "        'is complete_capital':int(sentence[index].upper()==sentence[index]),\n",
    "        'prev_word':'' if index==0 else sentence[index-1],\n",
    "        'next_word':'' if index==len(sentence)-1 else sentence[index + 1],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'prefix-4': sentence[index][:4],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'suffix-4': sentence[index][-3:],\n",
    "        'has_hyphen': '-' in sentence[index]\n",
    "    }  \n",
    "#note that for every word these many features are going to get generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untag(sentence): #we have to untag the sentence because we dont want tagged sentences for testing purposes\n",
    "    return[word for word,tag in sentence]\n",
    "def prepareData(tagged_Sentences): #preparing data for training set and test set\n",
    "    x,y=[],[]\n",
    "    for sentences in tagged_sentences:\n",
    "        x.append([features(untag(sentences),index) for index in range(len(sentences))])\n",
    "        y.append([tag for word,tag in sentences])\n",
    "    return x,y\n",
    "#y will have the word and y will have the tag. doing it for both training and testing dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = prepareData(train_set)\n",
    "x_test,y_test = prepareData(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Training Data [{'is_first_capital': 1, 'is_first_word': 1, 'is_last_word': 0, 'is complete_capital': 0, 'prev_word': '', 'next_word': 'Vinken', 'is_numeric': False, 'prefix-1': 'P', 'prefix-2': 'Pi', 'prefix-3': 'Pie', 'prefix-4': 'Pier', 'suffix-1': 'e', 'suffix-2': 're', 'suffix-3': 'rre', 'suffix-4': 'rre', 'has_hyphen': False}, {'is_first_capital': 1, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 0, 'prev_word': 'Pierre', 'next_word': ',', 'is_numeric': False, 'prefix-1': 'V', 'prefix-2': 'Vi', 'prefix-3': 'Vin', 'prefix-4': 'Vink', 'suffix-1': 'n', 'suffix-2': 'en', 'suffix-3': 'ken', 'suffix-4': 'ken', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 1, 'prev_word': 'Vinken', 'next_word': '61', 'is_numeric': False, 'prefix-1': ',', 'prefix-2': ',', 'prefix-3': ',', 'prefix-4': ',', 'suffix-1': ',', 'suffix-2': ',', 'suffix-3': ',', 'suffix-4': ',', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 1, 'prev_word': ',', 'next_word': 'years', 'is_numeric': True, 'prefix-1': '6', 'prefix-2': '61', 'prefix-3': '61', 'prefix-4': '61', 'suffix-1': '1', 'suffix-2': '61', 'suffix-3': '61', 'suffix-4': '61', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 0, 'prev_word': '61', 'next_word': 'old', 'is_numeric': False, 'prefix-1': 'y', 'prefix-2': 'ye', 'prefix-3': 'yea', 'prefix-4': 'year', 'suffix-1': 's', 'suffix-2': 'rs', 'suffix-3': 'ars', 'suffix-4': 'ars', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 0, 'prev_word': 'years', 'next_word': ',', 'is_numeric': False, 'prefix-1': 'o', 'prefix-2': 'ol', 'prefix-3': 'old', 'prefix-4': 'old', 'suffix-1': 'd', 'suffix-2': 'ld', 'suffix-3': 'old', 'suffix-4': 'old', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 1, 'prev_word': 'old', 'next_word': 'will', 'is_numeric': False, 'prefix-1': ',', 'prefix-2': ',', 'prefix-3': ',', 'prefix-4': ',', 'suffix-1': ',', 'suffix-2': ',', 'suffix-3': ',', 'suffix-4': ',', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 0, 'prev_word': ',', 'next_word': 'join', 'is_numeric': False, 'prefix-1': 'w', 'prefix-2': 'wi', 'prefix-3': 'wil', 'prefix-4': 'will', 'suffix-1': 'l', 'suffix-2': 'll', 'suffix-3': 'ill', 'suffix-4': 'ill', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 0, 'prev_word': 'will', 'next_word': 'the', 'is_numeric': False, 'prefix-1': 'j', 'prefix-2': 'jo', 'prefix-3': 'joi', 'prefix-4': 'join', 'suffix-1': 'n', 'suffix-2': 'in', 'suffix-3': 'oin', 'suffix-4': 'oin', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 0, 'prev_word': 'join', 'next_word': 'board', 'is_numeric': False, 'prefix-1': 't', 'prefix-2': 'th', 'prefix-3': 'the', 'prefix-4': 'the', 'suffix-1': 'e', 'suffix-2': 'he', 'suffix-3': 'the', 'suffix-4': 'the', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 0, 'prev_word': 'the', 'next_word': 'as', 'is_numeric': False, 'prefix-1': 'b', 'prefix-2': 'bo', 'prefix-3': 'boa', 'prefix-4': 'boar', 'suffix-1': 'd', 'suffix-2': 'rd', 'suffix-3': 'ard', 'suffix-4': 'ard', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 0, 'prev_word': 'board', 'next_word': 'a', 'is_numeric': False, 'prefix-1': 'a', 'prefix-2': 'as', 'prefix-3': 'as', 'prefix-4': 'as', 'suffix-1': 's', 'suffix-2': 'as', 'suffix-3': 'as', 'suffix-4': 'as', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 0, 'prev_word': 'as', 'next_word': 'nonexecutive', 'is_numeric': False, 'prefix-1': 'a', 'prefix-2': 'a', 'prefix-3': 'a', 'prefix-4': 'a', 'suffix-1': 'a', 'suffix-2': 'a', 'suffix-3': 'a', 'suffix-4': 'a', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 0, 'prev_word': 'a', 'next_word': 'director', 'is_numeric': False, 'prefix-1': 'n', 'prefix-2': 'no', 'prefix-3': 'non', 'prefix-4': 'none', 'suffix-1': 'e', 'suffix-2': 've', 'suffix-3': 'ive', 'suffix-4': 'ive', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 0, 'prev_word': 'nonexecutive', 'next_word': 'Nov.', 'is_numeric': False, 'prefix-1': 'd', 'prefix-2': 'di', 'prefix-3': 'dir', 'prefix-4': 'dire', 'suffix-1': 'r', 'suffix-2': 'or', 'suffix-3': 'tor', 'suffix-4': 'tor', 'has_hyphen': False}, {'is_first_capital': 1, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 0, 'prev_word': 'director', 'next_word': '29', 'is_numeric': False, 'prefix-1': 'N', 'prefix-2': 'No', 'prefix-3': 'Nov', 'prefix-4': 'Nov.', 'suffix-1': '.', 'suffix-2': 'v.', 'suffix-3': 'ov.', 'suffix-4': 'ov.', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 0, 'is complete_capital': 1, 'prev_word': 'Nov.', 'next_word': '.', 'is_numeric': True, 'prefix-1': '2', 'prefix-2': '29', 'prefix-3': '29', 'prefix-4': '29', 'suffix-1': '9', 'suffix-2': '29', 'suffix-3': '29', 'suffix-4': '29', 'has_hyphen': False}, {'is_first_capital': 0, 'is_first_word': 0, 'is_last_word': 1, 'is complete_capital': 1, 'prev_word': '29', 'next_word': '', 'is_numeric': False, 'prefix-1': '.', 'prefix-2': '.', 'prefix-3': '.', 'prefix-4': '.', 'suffix-1': '.', 'suffix-2': '.', 'suffix-3': '.', 'suffix-4': '.', 'has_hyphen': False}]\n"
     ]
    }
   ],
   "source": [
    "print('X Training Data',x_train[0]) #for each and every word we are generating the features to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Training Data ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.']\n"
     ]
    }
   ],
   "source": [
    "print('Y Training Data',y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritvi\\anaconda3\\lib\\site-packages\\sklearn\\base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.01, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crf is method based on gradient descent using l1 and l2 regularisation. you can check google\n",
    "crf=CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.01,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so the modelling part is now over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN',\n",
       " '.',\n",
       " 'NUM',\n",
       " 'ADJ',\n",
       " 'VERB',\n",
       " 'DET',\n",
       " 'ADP',\n",
       " 'CONJ',\n",
       " 'X',\n",
       " 'ADV',\n",
       " 'PRT',\n",
       " 'PRON']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           .       1.00      1.00      1.00     11715\n",
      "         ADJ       0.98      0.98      0.98      6397\n",
      "         ADP       0.99      1.00      0.99      9857\n",
      "         ADV       0.98      0.97      0.98      3171\n",
      "        CONJ       1.00      1.00      1.00      2265\n",
      "         DET       1.00      1.00      1.00      8725\n",
      "        NOUN       0.99      1.00      0.99     28867\n",
      "         NUM       1.00      1.00      1.00      3546\n",
      "        PRON       1.00      1.00      1.00      2737\n",
      "         PRT       0.99      0.99      0.99      3219\n",
      "        VERB       1.00      0.99      0.99     13564\n",
      "           X       1.00      1.00      1.00      6613\n",
      "\n",
      "    accuracy                           0.99    100676\n",
      "   macro avg       0.99      0.99      0.99    100676\n",
      "weighted avg       0.99      0.99      0.99    100676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9948845802375939"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.flat_accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('prefix-4:many', 'ADJ'), 7.773886),\n",
       " (('prev_word:will', 'VERB'), 7.499126),\n",
       " (('prev_word:would', 'VERB'), 6.490764),\n",
       " (('prefix-1:*', 'X'), 6.246508),\n",
       " (('suffix-2:ly', 'ADV'), 6.014297),\n",
       " (('prev_word:could', 'VERB'), 5.536372),\n",
       " (('prefix-4:Many', 'ADJ'), 5.534789),\n",
       " (('is_first_capital', 'NOUN'), 5.510457),\n",
       " (('prev_word:to', 'VERB'), 4.999606),\n",
       " (('next_word:Express', 'NOUN'), 4.658671)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(crf.state_features_).most_common(10) #to see the top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
